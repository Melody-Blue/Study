# 多线程渲染

&#8195;&#8195;**多线程渲染**是在**多线程编程**的基础之上提出并实现的一个功能，目的是提高资源使用效率。减小每一帧的渲染时长，从而使帧率变高。

&#8195;&#8195;学习进入**多线程渲染**知识之前，先了解一下**多线程编程**的基础知识。

## 多线程编程
------------------------------

### 1.1 多线程概述
------------------------------

&#8195;&#8195;多线程编程的思想在单核时代就已经出现了，Windows95已经支持多任务的功能（原理是在单核中切换不同的上下文，使每个进程中的线程都有时间获得执行指令的能力）

&#8195;&#8195;但是05年开始，单核主频接近4GHz的时候，发现了单核速度的是由极限的，单纯的主频提升已经无法明显提升整体性能了。

&#8195;&#8195;于是嘤特尔在05年发布了**奔腾D**和**奔腾4至尊版840**？系列，首次支持了两个物理级别的线程计算单元（虽然Inter在02年发布了超线程技术，也就是一核两线程，原先只用于Xeon处理器中。之后才陆续应用于奔腾4HT上，所以在奔腾D上是双核双线程的处理器）

&#8195;&#8195;AMD则是发布了**双核速龙(Athlon) 64 X2**处理器。

&#8195;&#8195;此后十多年，多核CPU得到蓬勃发展，现在最好的**AMD 3990X**已经是64核128线程了。

&#8195;&#8195;硬件的多核发展，给软件带来极大的发挥空间。程序可以充分发挥多核多线程的计算资源，所以各个领域也由此产生了多线程编程模型和技术。游戏方面，UnrealEngine等商业引擎也是利用多线程技术更充分的提升效率和效果。

&#8195;&#8195;使用多线程并发带来的作用总结起来有两点。

&#8195;&#8195;&#8195; 1：分离关注点：通过将相关的代码和无关的代码分离，可以使程序更容易理解和测试，减少出错的可能性，eg：文件加载，和网络传输放入单独的线程中去，及不妨碍主线程，又可以分离逻辑代码，清晰且易扩展。（PS：从代码角度来讲，模块化其实也可以做到这一点，但是在调试的时候，多线程是更容易看的。）

&#8195;&#8195;&#8195; 2：提升性能：相同数量级的任务，如果能分散到多个CPU中同时运行，必然会带来效率的提升。

&#8195;&#8195;随着CPU核心数量的提升，计算机获得的效益并非是直线提升的，而是遵循Amdahl's law（阿姆达尔定律）。
$$
{S}_{latency}(s) = \frac{1}{(1-p) + \frac{p}{s}}
$$
&#8195;&#8195;其中${S}_{latency}$是整个任务在多线程处理中理论上获得的加速比，s是线程数量，p是可并行处理的任务占比。比如我们的电脑是20线程的，处理一个可以80%并行处理的任务，理论加速比是
$$
{S}_{latency}(20) = \frac{1}{(1-0.8) + \frac{0.8}{20}} = 4.17
$$
&#8195;&#8195;所以多线程编程来的效益曲线如下所示；
![](多线程效益曲线图.png)
&#8195;&#8195;其中横向为线程数，纵向是加速比，四条线代表着四种有着不同多线程占比的任务。

&#8195;&#8195;由此可见当一个任务的并行处理率很多的情况下，开更多的线程处理这个任务，速度就越快。

&#8195;&#8195;eg：在编译UnrealEngine源码或者Shader的时候，基本是100%并行占比的，理论上所以越多核，编译效率越高。（原来公司的电脑8线程，需要早上来开始编译，下班编译好；现在的电脑20线程，一上午就🆗了。）

&#8195;&#8195;利用多线程并发提高性能的方式有两种：一种是**任务并行**：就是将单个任务分成几部分，且各自并行运行。（看起来直观，但是实际操作会很复杂，主要是各个部分之间有依赖）；第二种就是**数据并行**：指令相同，但是数据不同。

&#8195;&#8195; eg：假设我一个2D正方形（4个vec2d），需要经过缩放，旋转，平移，这个三个步骤，任务并行就是：一个缩放线程，一个旋转线程，一个平移线程，4个点分别经过三个线程然后输出；数据并行就是开四个线程，每个线程一个点，都执行缩放，旋转，平移的操作。

&#8195;&#8195;当然其实多线程并发不是只有益处的，也有一定的副作用（或者说我们在使用多线程时要注意的问题）：

+ **数据竞争**：多个线程会常常访问同一段代码，或者访问同一个资源，或者多喝CPU的高度缓存同步问题。会导致数据不同步或者读写错误而产生奇奇怪怪的异常结果。
+ **逻辑复杂化**：由于并发方式不唯一且不可预知。为了避免数据竞争，又会加入各种的同步操作，代码会相对离散，对于后续的维护会有阻碍，可能会引发小概率且难以重现的bug，增加查错难度。
+ **未必会提升效率**：并不是所有的东西，用多线程就可以节省资源的，通常和物理核心，同步机制，运行时状态，并发占比等等因素相关。（如果用的不好，反而降低效率，还不如不用）
------------------------------

### 1.2 多线程的一些核心概念
-------------------------------

+ **进程**：操作系统执行程序的基本单元和实体。 简单来讲就是一个程序的基本。拥有内核对象，地址空间，统计信息，若干线程。创建进程时自动创建一个主线程（unix来讲，其实不分主次，甚至操作系统不知道什么叫做线程，或者说线程更接近于lightweight processes/轻量级进程）。

            线程有优先级概念：windows下分：低（Low）、低于正常（Below normal）、正常（默认情况）（Normal）、高于正常（Above normal）、高（High）、实时（Real time）。

+ **线程**：真正执行代码的地方，不能独立存在，需要依附在某个进程内部。一个进程可以拥有多个线程，并且共享进程的数据，以便并行或并发的执行多个任务。

    单核CPU的调动方式，操作系统可能会采用轮询的方式进行调度。让他看起来是多线程同时运行的

    ![单核CPU](单核CPU.png "单核CPU")   
    多核CPU的调动方式

    ![多核CPU](多核CPU.png) 

    每个线程拥有自己的执行指令上下文（比如Windows下拥有IP（指令寄存器地址）和SP（栈起始寄存器地址）），执行栈，TLS（Thread Local Storage，线程局部缓存，用于创建临时变量等，线程开始时分配，结束时回收。）
    ![线程创建](线程创建.png)
    线程也存在优先级概念：Windows里是0（最低）-32（最高），JAVA里是1（最低）-10（最高）

    线程状态一般有运行，暂停状态。(c++细分的话是五种：新建状态(NEW),就绪状态(Runnable),运行状态(Running),阻塞状态(Blocked),死亡状态(Dead))

    ```c++
    Windows下对线程的两个函数。其中同个线程可以被多次暂停，如果想恢复的话需要运行同等次数的恢复函数。
    // 暂停/挂起线程
    DWORD SuspendThread(HANDLE hThread);
    // 继续/恢复运行线程
    DWORD ResumeThread(HANDLE hThread);
    ```

+ **携程**：一种轻量级（lightweight）的用户态线程，通常跑在同一个线程，利用同一个线程的不同时间片段执行指令，没有线程、进程切换和调度的开销。从使用者角度，可以利用协程机制实现在同个线程模拟异步的任务和编码方式。在同个线程内，它不会造成数据竞争，但也会因线程阻塞而阻塞。
+ **纤程**：如同协程，也是一种轻量级的用户态线程，可以使得应用程序独立决定自己的线程要如何运作。操作系统内核不知道纤程的存在，也不会为它进行调度。
+ **竞争条件**：同个进程允许有多个线程，这些线程可以共享进程的地址空间、数据结构和上下文。进程内的同一数据块，可能存在多个线程在某个很小的时间片段内同时读写，这就会造成数据异常，从而导致了不可预料的结果。这种不可预期性便造就了竞争条件（Race Condition）。

        避免产生竞争条件的技术有很多，诸如原子操作、临界区、读写锁、内核对象、信号量、互斥体、栅栏、屏障、事件等等。
+ **并行**：至少两个线程同时执行任务的机制。一般有多核多物理线程的CPU同时执行的行为，才可以叫并行，单核的多线程不能称之为并行。
+ **并发**：至少两个线程利用时间片（Timeslice）执行任务的机制，是并行的更普遍形式。即便单核CPU同时执行的多线程，也可称为并发。

    并行和并发的区别。

    ![](单双核对比.png)

    多核处理器可以同时存在并行和并发。
    
    ![](双核的并行并发.png)

+ **线程池**：线程池提供了一种新的任务并发的方式，调用者只需要传入一组可并行的任务和分组的策略，便可以使用线程池的若干线程并发地执行任务，使得调用者无需接直接触线程的调用和管理细节，降低了调用者的成本，也提升了线程的调度效率和吞吐量。

    不过，创建一个线程池时，几个关键性的设计问题会影响并发效率，比如：可使用的线程数量，高效的任务分配方式，以及是否需要等待一个任务完成。

    线程池可以自定义实现，也可以直接使用C++、操作系统或第三方库提供的API。
------------------------------

### 1.3 C++的多线程
------------------------------

&#8195;&#8195;C++11之前，C++的多线程支持近乎为零，直到C++11标准，多线程才真正纳入C++标准，并且提供相关关键字，STL标准库，用来方便实现跨平台的多线程调用。

#### **多线程关键字**
+ thread_local：C++是实现线程局部存储的关键，添加了此关键字的变量意味着每个线程都有自己的一份数据，不会共享同一份数据，避免数据竞争。

+ volatile：使用了volatile修饰符的变量意味着它在内存中的值可能随时发生变化，也告诉编译器不能做任何优化，每次使用到此变量的值都必须从内存中读取，而不应该直接使用寄存器的值。

+ std::atomic：严格来说atomic并不是关键字，而是STL的模板类，可以支持指定类型的原子操作。

#### **c++线程**
&#8195;&#8195;C++的线程类型是std::thread，接口如下

|  接口   | 解析  |
|  ----  | ----  |
| join  | 加入主线程，使得主线程强制等待该线程执行完。 |
| detach  | 从主线程分离，使得主线程无需等待该线程执行完。 |
| swap  | 与另外一个线程交换线程对象。 |
| joinable  | 查询是否可加入主线程。 |
| get_id  | 获取该线程的唯一标识符。 |
| native_handle  | 	返回实现层的线程句柄。 |
| hardware_concurrency  | 静态接口，返回硬件支持的并发线程数量。 |

#### **c++多线程同步**
&#8195;&#8195;线程同步的机制有很多，C++支持的有以下几种：
+ std::atomic
+ std::mutex
+ std::condition_variable
+ std::future
------------------------------

### 1.4 多线程实现机制
------------------------------


## 现代图形API的多线程特性。

------------------------------
### 2.1 传统图形API的多线程特性
------------------------------

&#8195;&#8195; OpenGL和DX10之前版本的图形API，所有的绘制指令是线性和阻塞式的，也就是说每次调用Draw接口后不会立刻返回且卡住调用线程。这种CPU和GPU的交互方式在单核时代影响不突出，但是随着多核时代到来，这种交互机制会严重影响运行性能。
![](传统图形渲染方式.png)

&#8195;&#8195; 单线程渲染器通常会导致单个CPU内核满负荷，其他的相对空闲，且帧率较低。（一个忙的要死，其余闲的睡着了，然后GPU表示，这工作量还行把。。就是有点枯燥）
![](多核单线程渲染.jpg)

&#8195;&#8195; 所以用传统API构架进行多线程渲染，必须从软件层面下手，开辟多个线程，用于单独处理逻辑和渲染指令，以便解除CPU和GPU的相互等待耦合，在SIGGraph2008有个Talk[(Practical Parallel Rendering with DirectX 9 and 10)](https://developer.amd.com/wordpress/media/2012/10/S2008-Scheib-ParallelRenderingSiggraph.pdf)专门讲解如何在DX9和DX10实现软件级别的多线程渲染，核心部分其实就是在软件层录制（Playback）DX的绘制命令（Command）。
![](软件层多线程渲染.png)

&#8195;&#8195;原理上就是我在CPU这边开辟一块空间，储存所有的指令和数据。然后由主线程收集好后统一调用图形API然后把执行相应指令并把数据拷贝到GPU去。

&#8195;&#8195;这种软件层面的命令录制问题很多：不支持部分图形API（eg：状态查询等），需要额外的命令缓存区记录绘制指令，命令阶段无法创建真正的GPU资源等等。

&#8195;&#8195;所以DX11开始尝试从硬件层面解决多线程渲染问题。支持了两种设备上下文：**即时上下文（Immediate Context）** 和 **延迟上下文（Deferred Context）**，不同的延迟上下文可以同时在不同的线程中使用，生成将在“即时上下文”中执行的命令列表。（原理和上述差不多。只不过DX把相应原理放到了图形API中，也就是从软件层面放到了硬件层面）
![](DX11的多线程.png)
&#8195;&#8195;不同的延迟上下文可以同时在不同的线程中使用，生成将在即时上下文中执行的命令列表。这种多线程策略允许将复杂的场景分解成并发任务。此外，延迟上下文在某些驱动的支持下可以实现硬件级别的加速从而不必再即时上下文中执行CommandList。

        由于CommandList内部会对已经录制的指令做高度的优化，执行这些优化后的指令会明显提升效率，比直接单独每条调用图形API会高校的多。所以使用延迟上下文的CommandList提前录制指令效率更高。

&#8195;&#8195;在DX11中，命令列表中的命令是被快速记录下来，而不是真正执行的，知道程序调用ExecuteCommandList方法才被GPU真正的执行，同时在这一代图形API中，ExcuteCommandList函数调用即返回，不需要等待，此时那些使用延迟渲染设备接口的CPU线程和主渲染线程可以去做别的事情，比如下一帧的碰撞检测，物理变化，动画插值，光照准备等等等等，从而为记录形成新的命令列表做准备。

&#8195;&#8195;不过基于DX11的多线程架构，由于硬件层面的加速不是必然支持，所有在延迟上下文记录的指令连同即时上下文的指令必须由同一个线程（通常是渲染线程）提交给GPU执行。

![](DX11多线程架构图.png)

&#8195;&#8195;所以DX11说是从尝试从硬件层上解决，实际上这种还是非硬件支持的。或者说这是从驱动层面支持多线程渲染。这种方式只是从 多线程录制指令 和 绘制同步等待 方面节省了部分CPU的时间，但是并不能从硬件层面真正发挥出多线程的威力。

------------------------------

### 2.2 Vulkan的多线程特性
------------------------------
&#8195;&#8195;作为跨平台图形API的新生代表Vulkan，有着摒弃了传统图形API的弊端，直面多核时代的优势，从而从设计和架构上就发挥了并行渲染的威力。

&#8195;&#8195;综合来看Vulkan和DX是非常相似的，存在CommandBuffer，CommandPool，CommandQueue和Fence等核心概念。并行模式也非常相似：在不同的CPU线程下并行的生成CommandBuffer指令，最后由主线程收集所有的CommandBuffer并提交至GPU：

![](Vulkan并行渲染.jpg)

&#8195;&#8195;Vulkan的CommandPool可以每帧被不同的线程创建，以便减少同步等待，提升并行效率：
![](命令池.jpg)

&#8195;&#8195; Semaphores（信号）用于同步Queue； Fence（栅栏）用于同步GPU和CPU； Event（事件）和Barrier（屏障）用于同步CommandBuffer
![](Vulkan同步.jpg)

------------------------------

### 2.3 DX12的多线程特性

### 2.4 Metal的多线程特性
------------------------------

## 游戏引擎的多线程渲染
------------------------------

### 3.1 Unity的多线程渲染
------------------------------
&#8195;&#8195; Unity的渲染体系中有几个核心概念，一个是Client，运行于主线程（逻辑线程），负责产生渲染指令；另一个WorkerThread，工作线程，用于协助处理主线程或生成渲染指令等各类子工作。Unity的渲染构架中支持一下几种模式：
+ Singlethreaded Rendering：单线程渲染模式，此模式下只有单个Client组件，没有工作线程。唯一的Client在主线程中产生所有的渲染命令（Rendering Command，RCMD），并且拥有图形设备对象，也会在主线程向图形设备产生调用图形API命令（Graphics API，GCMD）

![](Unity单线程.jpg)
这种模式下，CPU和GPU可能会互相等待，无法充分利用多核CPU，性能最差。

+ Multithreaded Rendering: 多线程渲染模式，这种模式下和单线程对比，就是多了一条工作线程，即用于生成GCMD的渲染线程，其中渲染线程跑的是GfxDeviceClient对象，专用于生成对应平台的图形API指令

![](Unity多线程.jpg)

+ Jobified Rendering：作业化渲染模式：此模式下有多个Client对象，单个渲染线程。此外，有多个作业对象，每个作业对象跑在专用独立的线程，用于生成即时图形命令（Intermediate Graphics Commands，IGCMD）。此外，还有一个工作（渲染）线程用于将作业线程生成的IGCMD转换成图形API的GCMD，运行示意图如下

![](Unity作业化.jpg)

+ Graphics Jobs：图形化作业渲染模式，此模式下有多个Client，多个工作线程，没有渲染线程。主线程上的多个Client对象驱动工作线程上的对应图形设备对象，直接生成GCMD，从而避免生成Jobified Rendering模式的IGCMD中间指令。只在支持硬件级多线程的图形API上可启动，如DX12,Vulkan等。

![](Unity多线程渲染.jpg)

&#8195;&#8195;所以其实Unity的四种渲染模式，也就是普通的图形API的渲染方式。

------------------------------

### 3.2 UE的多线程渲染
------------------------------

#### 3.2.1 UE的多线程渲染总览

&#8195;&#8195;默认情况下，UE存在游戏线程（GameThread），渲染线程（RenderThread），RHI线程（RHIThread），它们都独立地运行在专门的线程上（FRunnableThread）。

&#8195;&#8195;游戏线程通过某些接口向渲染线程的Queue入队回调接口，以便渲染线程稍后运行时，从渲染线程的Queue获取回调，一个个地执行，从而生成了CommandList。

&#8195;&#8195;渲染线程作为钱多（Frontend）生产的CommandList是平台无关的，抽象的图形API调用（也就是调用RHI模块的相关函数）；然后RHI线程作为后端（Backtend）会执行和转换渲染线程的CommandList成为指定图形API的调用（称之为GraphicalCommand）（具体就是DX12RHI,VulkanRHI，MetalRHI这种具体的模块），并提交到GPU执行。这些线程处理的数据通常是不同帧的（游戏线程处理下一帧，渲染线程和RHI线程处理这一帧）

&#8195;&#8195;也有特殊情况，比如渲染线程和RHI线程运行很快，几乎不存在延迟，这种情况下，游戏线程处理下一帧，渲染线程和RHI线程也可能处理下一帧（因为这一帧已经渲染完了），但是绝对不能是渲染线程拉后游戏线程一帧，这样游戏线程会卡住，等渲染线程完成这一帧操作之后，把下一帧的数据取过来，然后游戏线程才会接着再一下帧的操作。

![](UE4多线程渲染.jpg)
![](UE4RHI和Render.png)

&#8195;&#8195;开启多线程渲染带来的收益是帧率更高，帧间变化频率降低（帧率更稳定）。以Fortnite（堡垒之夜）移动端为例，在开启RHI线程之前，渲染线程急剧地上下波动，而加了RHI线程之后，波动平缓许多，和游戏线程基本保持一致，帧率也提升不少：
![](堡垒之夜.png)


#### 3.2.2 UE的多线程编程

&#8195;&#8195;UE由于很多轮子都是Epic公司自己造的，所以将UE的多线程渲染，首先要熟悉UE的一些多线相关的轮子：

##### 3.2.2.1 UE的多线程基础

+ TAtomic：功能和C++的Atomic类似。
```C++
// Engine\Source\Runtime\Core\Public\Templates\Atomic.h

//模板类，但是只对基本类型生效，通过父类TAtomicBaseType_T来达到检测目的
template <typename T>
class TAtomic final : public UE4Atomic_Private::TAtomicBaseType_T<T>
{
    static_assert(TIsTrivial<T>::Value, "TAtomic is only usable with trivial types");
    
    (......)
}

//加载操作
template <typename T>
FORCEINLINE T Load(const volatile T* Element)
{
    // 采取平台相关的接口加载原子值.
    auto Result = FPlatformAtomics::AtomicRead((volatile TUnderlyingIntegerType_T<T>*)Element);
    return *(const T*)&Result;
}

//存储
template <typename T>
FORCEINLINE void Store(const volatile T* Element, T Value)
{
    // 采取平台相关的接口存储原子值.
    FPlatformAtomics::InterlockedExchange((volatile TUnderlyingIntegerType_T<T>*)Element, *(const TUnderlyingIntegerType_T<T>*)&Value);
}

//原子替换
template <typename T>
FORCEINLINE T Exchange(volatile T* Element, T Value)
{
    // 采取平台相关的接口交换原子值.
    auto Result = FPlatformAtomics::InterlockedExchange((volatile TUnderlyingIntegerType_T<T>*)Element, *(const TUnderlyingIntegerType_T<T>*)&Value);
    return *(const T*)&Result;
}

//内存顺序上，只有两种模式
enum class EMemoryOrder
{
    Relaxed,                // 顺序松散, 不会引起重排序
    SequentiallyConsistent  // 顺序一致
};
//C++有六种
enum memory_order{
    memory_order_relaxed;   //自由顺序
    memory_order_consume;   //消费操作
    memory_order_acquire;   //“获取”内存顺序
    memory_order_release;   //“释放”内存顺序
    memory_order_acq_rel;   //"获取释放"内存顺序
    memory_order_seq_cst;   //一直顺序
}

```

+ TFuture：也是类似C++的Future和Promise对象，是模板类，抽象了返回值类型。
```C++
// Engine\Source\Runtime\Core\Public\Async\Future.h

template<typename InternalResultType>
class TFutureBase
{
public:
    bool IsReady() const;
    bool IsValid() const;

    void Wait() const
    {
        if (State.IsValid())
        {
            while (!WaitFor(FTimespan::MaxValue()));
        }
    }
    bool WaitFor(const FTimespan& Duration) const
    {
        return State.IsValid() ? State->WaitFor(Duration) : false;
    }
    bool WaitUntil(const FDateTime& Time) const
    {
        return WaitFor(Time - FDateTime::UtcNow());
    }

protected:
    typedef TSharedPtr<TFutureState<InternalResultType>, ESPMode::ThreadSafe> StateType;

    const StateType& GetState() const;

    template<typename Func>
    auto Then(Func Continuation);

    template<typename Func>
    auto Next(Func Continuation);

    void Reset();

private:

    /** Holds the future's state. */
    StateType State;
};

template<typename ResultType>
class TFuture : public TFutureBase<ResultType>
{
    typedef TFutureBase<ResultType> BaseType;

public:

    ResultType Get() const
    {
        return this->GetState()->GetResult();
    }

    TSharedFuture<ResultType> Share()
    {
        return TSharedFuture<ResultType>(MoveTemp(*this));
    }
};
```

+ TPromise：通常是和TFuture配合使用的
```C++
template<typename InternalResultType>
class TPromiseBase : FNoncopyable
{
    typedef TSharedPtr<TFutureState<InternalResultType>, ESPMode::ThreadSafe> StateType;

    (......)
    
protected:
    const StateType& GetState();

private:
    StateType State; // 存储了Future的状态.
};

template<typename ResultType>
class TPromise : public TPromiseBase<ResultType>
{
public:
    typedef TPromiseBase<ResultType> BaseType;

public:
    // 获取Future对象
    TFuture<ResultType> GetFuture()
    {
        check(!FutureRetrieved);
        FutureRetrieved = true;

        return TFuture<ResultType>(this->GetState());
    }
    
    // 设置Future的值
    FORCEINLINE void SetValue(const ResultType& Result)
    {
        EmplaceValue(Result);
    }

    FORCEINLINE void SetValue(ResultType&& Result)
    {
        EmplaceValue(MoveTemp(Result));
    }

    template<typename... ArgTypes>
    void EmplaceValue(ArgTypes&&... Args)
    {
        this->GetState()->EmplaceResult(Forward<ArgTypes>(Args)...);
    }

private:
    bool FutureRetrieved;
};
```

+ ParallelFor：UE内置的支持多线程并行处理任务的For循环。支持以下几种并行方式：
```C++
enum class EParallelForFlags
{
    None, // 默认并行方式
    ForceSingleThread = 1, // 强制单线程, 常用于调试.
    Unbalanced = 2, // 非任务平衡, 常用于具有高度可变计算时间的任务.
    PumpRenderingThread = 4, // 注入渲染线程. 如果是在渲染线程调用, 需要保证ProcessThread空闲状态.
};

//相关函数
inline void ParallelFor(int32 Num, TFunctionRef<void(int32)> Body, bool bForceSingleThread, bool bPumpRenderingThread=false);

inline void ParallelFor(int32 Num, TFunctionRef<void(int32)> Body, EParallelForFlags Flags = EParallelForFlags::None);

template<typename FunctionType>
inline void ParallelForTemplate(int32 Num, const FunctionType& Body, EParallelForFlags Flags = EParallelForFlags::None);

inline void ParallelForWithPreWork(int32 Num, TFunctionRef<void(int32)> Body, TFunctionRef<void()> CurrentThreadWorkToDoBeforeHelping, bool bForceSingleThread, bool bPumpRenderingThread = false);

inline void ParallelForWithPreWork(int32 Num, TFunctionRef<void(int32)> Body, TFunctionRef<void()> CurrentThreadWorkToDoBeforeHelping, EParallelForFlags Flags = EParallelForFlags::None);

----------------------------------------------------------------------------
eg:    ParallelFor(AddPrimitiveBatches.Num(), // 数量
        [&](int32 Index)                      // 回调函数, Index返回索引
        {
            if (!AddPrimitiveBatches[Index]->IsPendingKill())
            {
                Scene->AddPrimitive(AddPrimitiveBatches[Index]);
            }
        },
        !FApp::ShouldUseThreadingForPerformance() // 是否多线程处理
    );
```

##### 3.2.2 UE的多线程实现

&#8195;&#8195;UE的多线程实现上并没有采纳C++11标准库那一套，而是从自己的系统级做了封装和实现，包括系统线程，线程池，异步任务，任务图以及相关的通知同步机制。


#### 3.2.3 UE的多线程渲染

+ 游戏线程

&#8195;&#8195;其实把主线程、游戏线程和TaskGraph系统的ENamedThreads::GameThread其实是一回事，都是同一个线程。

&#8195;&#8195;（TaskGraph是UE自带的并行任务系统，直译是任务图，使用的是有向非循环图，可以指定依赖关系，指定前序，后序任务，但是不能有循环依赖）

&#8195;&#8195;先初始化和设置，其他地方就可以通过TaskGraph系统并行的处理任务了，也可以访问全局变量来判断游戏线程是否初始化结束以及当前线程是否为游戏线程。
```C++
// Engine\Source\Runtime\Launch\Private\LaunchEngineLoop.cpp

int32 FEngineLoop::PreInitPreStartupScreen(const TCHAR* CmdLine)
{
    (......)
    
    // 获取当前线程id, 存储到全局变量中.
    GGameThreadId = FPlatformTLS::GetCurrentThreadId();
    GIsGameThreadIdInitialized = true;

    FPlatformProcess::SetThreadAffinityMask(FPlatformAffinity::GetMainGameMask());
    // 设置游戏线程数据(但很多平台都是空的实现体)
    FPlatformProcess::SetupGameThread();
    
    (......)
    
    if (bCreateTaskGraphAndThreadPools)
    {
        SCOPED_BOOT_TIMING("FTaskGraphInterface::Startup");
        FTaskGraphInterface::Startup(FPlatformMisc::NumberOfCores());
        // 将当前线程(主线程)附加到TaskGraph的GameThread命名插槽中. 这样主线程便和TaskGraph联动了起来.
        FTaskGraphInterface::Get().AttachToThread(ENamedThreads::GameThread);
    }
}

bool IsInGameThread()
{
    return GIsGameThreadIdInitialized && FPlatformTLS::GetCurrentThreadId() == GGameThreadId;
}
```

+ 渲染（Render）线程

&#8195;&#8195;渲染线程和游戏不同，是一条专门用于生成渲染指令和渲染逻辑的独立线程。
```C++
// Engine\Source\Runtime\RenderCore\Public\RenderingThread.h

// 是否启用了独立的渲染线程, 如果为false, 则所有渲染命令会被立即执行, 而不是放入渲染命令队列.
extern RENDERCORE_API bool GIsThreadedRendering;

// 渲染线程是否应该被创建. 通常被命令行参数或ToggleRenderingThread控制台参数设置.
extern RENDERCORE_API bool GUseThreadedRendering;

// 是否开启RHI线程
extern RENDERCORE_API void SetRHIThreadEnabled(bool bEnableDedicatedThread, bool bEnableRHIOnTaskThreads);

(......)

//StartRenderingThread()是在FEngineLoop::PreInitPostStartupScreen中调用的。
// 开启渲染线程.
extern RENDERCORE_API void StartRenderingThread();

// 停止渲染线程.
extern RENDERCORE_API void StopRenderingThread();

// 检查渲染线程是否健康(是否Crash), 如果crash, 则会用UE_Log输出日志.
extern RENDERCORE_API void CheckRenderingThreadHealth();

// 检查渲染线程是否健康(是否Crash)
extern RENDERCORE_API bool IsRenderingThreadHealthy();

// 增加一个必须在下一个场景绘制前或flush渲染命令前完成的任务.
extern RENDERCORE_API void AddFrameRenderPrerequisite(const FGraphEventRef& TaskToAdd);

// 手机帧渲染前序任务, 保证所有渲染命令被入队.
extern RENDERCORE_API void AdvanceFrameRenderPrerequisite();

// 等待所有渲染线程的渲染命令被执行完毕. 会卡住游戏线程, 只能被游戏线程调用.
extern RENDERCORE_API void FlushRenderingCommands(bool bFlushDeferredDeletes = false);

extern RENDERCORE_API void FlushPendingDeleteRHIResources_GameThread();
extern RENDERCORE_API void FlushPendingDeleteRHIResources_RenderThread();

extern RENDERCORE_API void TickRenderingTickables();

extern RENDERCORE_API void StartRenderCommandFenceBundler();
extern RENDERCORE_API void StopRenderCommandFenceBundler();

// 向渲染线程入队渲染指令, Type指明了渲染操作的名字.
#define ENQUEUE_RENDER_COMMAND(Type) \
    struct Type##Name \
    {  \
        static const char* CStr() { return #Type; } \
        static const TCHAR* TStr() { return TEXT(#Type); } \
    }; \
    EnqueueUniqueRenderCommand<Type##Name>
```

+ RHI线程

&#8195;&#8195;RHI线程的工作是转换渲染指令到指定图形API，创建、上传渲染资源到GPU。它的主要逻辑在FRHIThread中。

```C++
// Engine\Source\Runtime\RenderCore\Private\RenderingThread.cpp

class FRHIThread : public FRunnable
{
public:
    FRunnableThread* Thread;    // 所在的RHI线程.

    FRHIThread()
        : Thread(nullptr)
    {
        check(IsInGameThread());
    }
    
    void Start()
    {
        // 开始时创建RHI线程.
        Thread = FRunnableThread::Create(this, TEXT("RHIThread"), 512 * 1024, FPlatformAffinity::GetRHIThreadPriority(),
            FPlatformAffinity::GetRHIThreadMask(), FPlatformAffinity::GetRHIThreadFlags()
            );
        check(Thread);
    }

    virtual uint32 Run() override
    {
        LLM_SCOPE(ELLMTag::RHIMisc);
        
        // 初始化TLS
        FMemory::SetupTLSCachesOnCurrentThread();
        // 将FRHIThread所在的RHI线程附加到askGraph体系中，并指定到ENamedThreads::RHIThread。
        FTaskGraphInterface::Get().AttachToThread(ENamedThreads::RHIThread);
        // 启动RHI线程，直到线程返回。
        FTaskGraphInterface::Get().ProcessThreadUntilRequestReturn(ENamedThreads::RHIThread);
        // 清理TLS.
        FMemory::ClearAndDisableTLSCachesOnCurrentThread();
        return 0;
    }
    
    // 单例接口。
    static FRHIThread& Get()
    {
        static FRHIThread Singleton; // 使用了局部静态变量，可以保证线程安全。
        return Singleton;
    }
};
```
&#8195;&#8195;渲染线程是通过RHICommandList向RHI线程入队任务的,所有的RHI指令都是预先声明并实现好的，渲染线程创建这些声明好的RHI指令即可在合适的被推入RHI线程队列并被执行。

```C++
// Engine\Source\Runtime\RHI\Public\RHICommandList.h

// RHI命令父类
struct FRHICommandBase
{
    FRHICommandBase* Next = nullptr; // 指向下一条RHI命令.
    // 执行RHI命令并销毁.
    virtual void ExecuteAndDestruct(FRHICommandListBase& CmdList, FRHICommandListDebugContext& DebugContext) = 0;
};

// RHI命令结构体
template<typename TCmd, typename NameType = FUnnamedRhiCommand>
struct FRHICommand : public FRHICommandBase
{
    (......)

    void ExecuteAndDestruct(FRHICommandListBase& CmdList, FRHICommandListDebugContext& Context) override final
    {
        (......)
        
        TCmd *ThisCmd = static_cast<TCmd*>(this);

        ThisCmd->Execute(CmdList);
        ThisCmd->~TCmd();
    }
};

// 向RHI线程发送RHI命令的宏.
#define FRHICOMMAND_MACRO(CommandName)                                \
struct PREPROCESSOR_JOIN(CommandName##String, __LINE__)                \
{                                                                    \
    static const TCHAR* TStr() { return TEXT(#CommandName); }        \
};                                                                    \
struct CommandName final : public FRHICommand<CommandName, PREPROCESSOR_JOIN(CommandName##String, __LINE__)>


//全部的指令有近百种，这些事其中一部分
FRHICOMMAND_MACRO(FRHICommandSetStereoViewport)
FRHICOMMAND_MACRO(FRHICommandSetScissorRect)
FRHICOMMAND_MACRO(FRHICommandSetRenderTargets)
FRHICOMMAND_MACRO(FRHICommandBeginRenderPass)
FRHICOMMAND_MACRO(FRHICommandEndRenderPass)
FRHICOMMAND_MACRO(FRHICommandNextSubpass)
FRHICOMMAND_MACRO(FRHICommandBeginParallelRenderPass)
FRHICOMMAND_MACRO(FRHICommandEndParallelRenderPass)
FRHICOMMAND_MACRO(FRHICommandBeginRenderSubPass)
```

+ 游戏线程和渲染线程的同步

&#8195;&#8195;之前说游戏线程不可能领先于渲染线程超过一帧，否则游戏线程会等待渲染线程处理完。所以同步这个事情比较关键

```C++
void FEngineLoop::Tick()
{
    (......)
    
    // 在引擎循环的帧末尾添加游戏线程和渲染线程的同步事件.
    {
        static FFrameEndSync FrameEndSync; // 局部静态变量, 线程安全.
        static auto CVarAllowOneFrameThreadLag = IConsoleManager::Get().FindTConsoleVariableDataInt(TEXT("r.OneFrameThreadLag"));
        // 同步游戏和渲染线程, 是否允许一帧的延迟可由控制台命令控制. 默认是开启的.
        FrameEndSync.Sync( CVarAllowOneFrameThreadLag->GetValueOnGameThread() != 0 );
    }
    
    (......)
}



// Engine\Source\Runtime\RenderCore\Public\RenderCommandFence.h

// 渲染命令栅栏
class RENDERCORE_API FRenderCommandFence
{
public:
    // 向渲染命令队列增加一个栅栏. bSyncToRHIAndGPU是否同步RHI和GPU交换Buffer, 否则只等待渲染线程.
    void BeginFence(bool bSyncToRHIAndGPU = false); 

    // 等待栅栏被执行. bProcessGameThreadTasks没有作用.
    void Wait(bool bProcessGameThreadTasks = false) const;

    // 是否完成了栅栏.
    bool IsFenceComplete() const;

private:
    mutable FGraphEventRef CompletionEvent; // 处理完成同步的事件
    ENamedThreads::Type TriggerThreadIndex; // 处理完之后需要触发的线程类型.
};

// Engine\Source\Runtime\Engine\Public\UnrealEngine.h
class FFrameEndSync
{
    FRenderCommandFence Fence[2]; // 渲染栅栏对.
    int32 EventIndex; // 当前事件索引
public:
    // 同步游戏线程和渲染线程. bAllowOneFrameThreadLag是否允许渲染线程一帧的延迟.
    void Sync( bool bAllowOneFrameThreadLag )
    {
        Fence[EventIndex].BeginFence(true); // 开启栅栏, 强制同步RHI和GPU交换链的.

        bool bEmptyGameThreadTasks = !FTaskGraphInterface::Get().IsThreadProcessingTasks(ENamedThreads::GameThread);
        
        // 保证游戏线程至少跑过一次任务.
        if (bEmptyGameThreadTasks)
        {
            FTaskGraphInterface::Get().ProcessThreadUntilIdle(ENamedThreads::GameThread);
        }

        // 如果允许延迟, 交换事件索引.
        if( bAllowOneFrameThreadLag )
        {
            EventIndex = (EventIndex + 1) % 2;
        }

        (......)
        
        // 开启栅栏等待.
        Fence[EventIndex].Wait(bEmptyGameThreadTasks);
    }
};
```